url,title,github-author,github-link,date,abstract,star,tasks
https://paperswithcode.com/paper/matching-anything-by-segmenting-anything,Matching Anything by Segmenting Anything,siyuanliii/masa,https://github.com/siyuanliii/masa,6 Jun 2024,"The robust association of the same objects across video frames in complex scenes is crucial for many applications, especially Multiple Object Tracking (MOT).",260,"Multiple Object Tracking,Domain Generalization"
https://paperswithcode.com/paper/llava-uhd-an-lmm-perceiving-any-aspect-ratio,LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images,openbmb/omnilmm,https://github.com/openbmb/omnilmm,18 Mar 2024,"To address the challenges, we present LLaVA-UHD, a large multimodal model that can efficiently perceive images in any aspect ratio and high resolution.","6,757",Other
https://paperswithcode.com/paper/buffer-of-thoughts-thought-augmented,Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models,yangling0818/buffer-of-thought-llm,https://github.com/yangling0818/buffer-of-thought-llm,6 Jun 2024,"We introduce Buffer of Thoughts (BoT), a novel and versatile thought-augmented reasoning approach for enhancing accuracy, efficiency and robustness of large language models (LLMs).",167,"Code Generation,Arithmetic Reasoning"
https://paperswithcode.com/paper/vision-lstm-xlstm-as-generic-vision-backbone,Vision-LSTM: xLSTM as Generic Vision Backbone,NX-AI/vision-lstm,https://github.com/NX-AI/vision-lstm,6 Jun 2024,"Transformers are widely used as generic backbones in computer vision, despite initially introduced for natural language processing.",203,Other
https://paperswithcode.com/paper/fast-timing-conditioned-latent-audio,Fast Timing-Conditioned Latent Audio Diffusion,stability-ai/stable-audio-tools,https://github.com/stability-ai/stable-audio-tools,7 Feb 2024,Generating long-form 44. 1kHz stereo audio from text prompts can be computationally demanding.,"1,832",Audio Generation
https://paperswithcode.com/paper/streamspeech-simultaneous-speech-to-speech,StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task Learning,ictnlp/streamspeech,https://github.com/ictnlp/streamspeech,5 Jun 2024,"Simultaneous speech-to-speech translation (Simul-S2ST, a. k. a streaming speech translation) outputs target speech while receiving streaming speech inputs, which is critical for real-time communication.",222,"Multi-Task Learning,Automatic Speech Recognition (ASR)"
https://paperswithcode.com/paper/detikzify-synthesizing-graphics-programs-for,DeTikZify: Synthesizing Graphics Programs for Scientific Figures and Sketches with TikZ,potamides/detikzify,https://github.com/potamides/detikzify,24 May 2024,"Creating high-quality scientific figures can be time-consuming and challenging, even though sketching ideas on paper is relatively easy.",379,Language Modelling
https://paperswithcode.com/paper/scalable-matmul-free-language-modeling,Scalable MatMul-free Language Modeling,ridgerchu/matmulfreellm,https://github.com/ridgerchu/matmulfreellm,4 Jun 2024,Our experiments show that our proposed MatMul-free models achieve performance on-par with state-of-the-art Transformers that require far more memory during inference at a scale up to at least 2. 7B parameters.,733,Language Modelling
https://paperswithcode.com/paper/agentgym-evolving-large-language-model-based,AgentGym: Evolving Large Language Model-based Agents across Diverse Environments,woooodyy/agentgym,https://github.com/woooodyy/agentgym,6 Jun 2024,Building generalist agents that can handle diverse tasks and evolve themselves across different environments is a long-term goal in the AI community.,92,"Large Language Model,Language Modelling"
https://paperswithcode.com/paper/flash-diffusion-accelerating-any-conditional,Flash Diffusion: Accelerating Any Conditional Diffusion Model for Few Steps Image Generation,gojasper/flash-diffusion,https://github.com/gojasper/flash-diffusion,4 Jun 2024,"In this paper, we propose an efficient, fast, and versatile distillation method to accelerate the generation of pre-trained diffusion models: Flash Diffusion.",144,"Image Inpainting,Face Swapping"
https://paperswithcode.com/paper/blind-image-restoration-via-fast-diffusion-2,Blind Image Restoration via Fast Diffusion Inversion,hamadichihaoui/BIRD,https://github.com/hamadichihaoui/BIRD,29 May 2024,This is ultimately equivalent to casting the IR task as an optimization problem in the space of the input noise.,137,Image Restoration
https://paperswithcode.com/paper/scaling-and-evaluating-sparse-autoencoders,Scaling and evaluating sparse autoencoders,openai/sparse_autoencoder,https://github.com/openai/sparse_autoencoder,6 Jun 2024,"Using these techniques, we find clean scaling laws with respect to autoencoder size and sparsity.",453,Language Modelling
https://paperswithcode.com/paper/orbit-a-unified-simulation-framework-for,Orbit: A Unified Simulation Framework for Interactive Robot Learning Environments,NVIDIA-Omniverse/Orbit,https://github.com/NVIDIA-Omniverse/Orbit,10 Jan 2023,"We present Orbit, a unified and modular framework for robot learning powered by NVIDIA Isaac Sim.","1,291","Motion Planning,Imitation Learning"
https://paperswithcode.com/paper/hipporag-neurobiologically-inspired-long-term,HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models,osu-nlp-group/hipporag,https://github.com/osu-nlp-group/hipporag,23 May 2024,"In order to thrive in hostile and ever-changing natural environments, mammalian brains evolved to store large amounts of knowledge about the world and continually integrate new information while avoiding catastrophic forgetting.",482,"Knowledge Graphs,Hippocampus"
https://paperswithcode.com/paper/real-time-transformer-based-open-vocabulary,Real-time Transformer-based Open-Vocabulary Detection with Efficient Fusion Head,om-ai-lab/OmDet,https://github.com/om-ai-lab/OmDet,11 Mar 2024,End-to-end transformer-based detectors (DETRs) have shown exceptional performance in both closed-set and open-vocabulary object detection (OVD) tasks through the integration of language modalities.,522,"Real-Time Object Detection,Open Vocabulary Object Detection"
https://paperswithcode.com/paper/switch-transformers-scaling-to-trillion,Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity,vikparuchuri/marker,https://github.com/vikparuchuri/marker,11 Jan 2021,We design models based off T5-Base and T5-Large to obtain up to 7x increases in pre-training speed with the same computational resources.,"11,752","Question Answering,Language Modelling"
https://paperswithcode.com/paper/easyanimate-a-high-performance-long-video,EasyAnimate: A High-Performance Long Video Generation Method based on Transformer Architecture,aigc-apps/easyanimate,https://github.com/aigc-apps/easyanimate,29 May 2024,The motion module can be adapted to various DiT baseline methods to generate video with different styles.,506,"Video Generation,Image Generation"
https://paperswithcode.com/paper/mobile-agent-v2-mobile-device-operation,Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration,x-plug/mobileagent,https://github.com/x-plug/mobileagent,3 Jun 2024,"However, the two major navigation challenges in mobile device operation tasks, task progress navigation and focus content navigation, are significantly complicated under the single-agent architecture of existing work.","2,047",Other
https://paperswithcode.com/paper/x-lora-mixture-of-low-rank-adapter-experts-a,"X-LoRA: Mixture of Low-Rank Adapter Experts, a Flexible Framework for Large Language Models with Applications in Protein Mechanics and Molecular Design",ericlbuehler/mistral.rs,https://github.com/ericlbuehler/mistral.rs,11 Feb 2024,"Starting with a set of pre-trained LoRA adapters, our gating strategy uses the hidden states to dynamically mix adapted layers, allowing the resulting X-LoRA model to draw upon different capabilities and create never-before-used deep layer-wise combinations to solve tasks.","1,832","Knowledge Graphs,graph construction"
https://paperswithcode.com/paper/a-bench-are-lmms-masters-at-evaluating-ai,A-Bench: Are LMMs Masters at Evaluating AI-generated Images?,q-future/a-bench,https://github.com/q-future/a-bench,5 Jun 2024,How to accurately and efficiently assess AI-generated images (AIGIs) remains a critical challenge for generative models.,68,Other
https://paperswithcode.com/paper/how-far-are-we-to-gpt-4v-closing-the-gap-to,How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites,opengvlab/internvl,https://github.com/opengvlab/internvl,25 Apr 2024,"Compared to both open-source and proprietary models, InternVL 1. 5 shows competitive performance, achieving state-of-the-art results in 8 of 18 benchmarks.","3,371","Language Modelling,4k"
https://paperswithcode.com/paper/pre-training-small-base-lms-with-fewer-tokens,Pre-training Small Base LMs with Fewer Tokens,Lightning-AI/lit-gpt,https://github.com/Lightning-AI/lit-gpt,12 Apr 2024,Here we show that smaller LMs trained utilizing some of the layers of GPT2-medium (355M) and GPT-2-large (770M) can effectively match the val loss of their bigger counterparts when trained from scratch for the same number of training steps on OpenWebText dataset with 9B tokens.,"7,627",Language Modelling
https://paperswithcode.com/paper/reno-enhancing-one-step-text-to-image-models,ReNO: Enhancing One-step Text-to-Image Models through Reward-based Noise Optimization,explainableml/reno,https://github.com/explainableml/reno,6 Jun 2024,"Moreover, given the same computational resources, a ReNO-optimized one-step model outperforms widely-used open-source models such as SDXL and PixArt-$\alpha$, highlighting the efficiency and effectiveness of ReNO in enhancing T2I model performance at inference time.",35,Other
https://paperswithcode.com/paper/stable-pose-leveraging-transformers-for-pose,Stable-Pose: Leveraging Transformers for Pose-Guided Text-to-Image Generation,ai-med/stablepose,https://github.com/ai-med/stablepose,4 Jun 2024,Controllable text-to-image (T2I) diffusion models have shown impressive performance in generating high-quality visual content through the incorporation of various conditions.,62,Text-to-Image Generation
https://paperswithcode.com/paper/dragonfly-multi-resolution-zoom-supercharges,Dragonfly: Multi-Resolution Zoom Supercharges Large Visual-Language Model,togethercomputer/dragonfly,https://github.com/togethercomputer/dragonfly,3 Jun 2024,"Recent advances in large multimodal models (LMMs) suggest that higher image resolution enhances the fine-grained understanding of image details, crucial for tasks such as visual commonsense reasoning and analyzing biomedical images.",42,"Language Modelling,Image Captioning"
https://paperswithcode.com/paper/improving-alignment-and-robustness-with-short,Improving Alignment and Robustness with Short Circuiting,blackswan-ai/short-circuiting,https://github.com/blackswan-ai/short-circuiting,6 Jun 2024,"Existing techniques aimed at improving alignment, such as refusal training, are often bypassed.",35,Adversarial Robustness
https://paperswithcode.com/paper/mofa-video-controllable-image-animation-via,MOFA-Video: Controllable Image Animation via Generative Motion Field Adaptions in Frozen Image-to-Video Diffusion Model,myniuuu/mofa-video,https://github.com/myniuuu/mofa-video,30 May 2024,"We present MOFA-Video, an advanced controllable image animation method that generates video from the given image using various additional controllable signals (such as human landmarks reference, manual trajectories, and another even provided video) or their combinations.",136,"Video Generation,Image Animation"
https://paperswithcode.com/paper/yolov10-real-time-end-to-end-object-detection,YOLOv10: Real-Time End-to-End Object Detection,THU-MIG/yolov10,https://github.com/THU-MIG/yolov10,23 May 2024,"In this work, we aim to further advance the performance-efficiency boundary of YOLOs from both the post-processing and model architecture.","7,199","Object,Data Augmentation"
https://paperswithcode.com/paper/coarse-to-fine-tensor-trains-for-compact,Coarse-To-Fine Tensor Trains for Compact Visual Representations,sebulo/PuTT,https://github.com/sebulo/PuTT,6 Jun 2024,This has prevented practitioners from deploying the full potential of tensor networks for visual data.,31,"Denoising,3D Reconstruction"
https://paperswithcode.com/paper/megactor-harness-the-power-of-raw-video-for,MegActor: Harness the Power of Raw Video for Vivid Portrait Animation,megvii-research/megfaceanimate,https://github.com/megvii-research/megfaceanimate,31 May 2024,"Despite raw driving videos contain richer information on facial expressions than intermediate representations such as landmarks in the field of portrait animation, they are seldom the subject of research.",104,"Synthetic Data Generation,Style Transfer"
https://paperswithcode.com/paper/hunyuan-dit-a-powerful-multi-resolution,Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding,tencent/hunyuandit,https://github.com/tencent/hunyuandit,14 May 2024,"For fine-grained language understanding, we train a Multimodal Large Language Model to refine the captions of the images.","2,206","Language Modelling,Image Generation"
https://paperswithcode.com/paper/glace-global-local-accelerated-coordinate,GLACE: Global Local Accelerated Coordinate Encoding,cvg/glace,https://github.com/cvg/glace,6 Jun 2024,"We propose GLACE, which integrates pre-trained global and local encodings and enables SCR to scale to large scenes with only a single small-sized network.",27,"Position,Pose Estimation"
https://paperswithcode.com/paper/tokenhmr-advancing-human-mesh-recovery-with-a,TokenHMR: Advancing Human Mesh Recovery with a Tokenized Pose Representation,saidwivedi/TokenHMR,https://github.com/saidwivedi/TokenHMR,25 Apr 2024,"We address the problem of regressing 3D human pose and shape from a single image, with a focus on 3D accuracy.",117,"Human Mesh Recovery,3D Human Pose Estimation"
https://paperswithcode.com/paper/scedit-efficient-and-controllable-image,SCEdit: Efficient and Controllable Image Diffusion Generation via Skip Connection Editing,modelscope/swift,https://github.com/modelscope/swift,18 Dec 2023,"Image diffusion models have been utilized in various tasks, such as text-to-image generation and controllable image synthesis.","1,849","Text-to-Image Generation,Decoder"
https://paperswithcode.com/paper/videotetris-towards-compositional-text-to,VideoTetris: Towards Compositional Text-to-Video Generation,yangling0818/videotetris,https://github.com/yangling0818/videotetris,6 Jun 2024,Diffusion models have demonstrated great success in text-to-video (T2V) generation.,44,"Text-to-Video Generation,Denoising"
https://paperswithcode.com/paper/cv-vae-a-compatible-video-vae-for-latent,CV-VAE: A Compatible Video VAE for Latent Generative Video Models,ailab-cvc/cv-vae,https://github.com/ailab-cvc/cv-vae,30 May 2024,"Moreover, since current diffusion-based approaches are often implemented using pre-trained text-to-image (T2I) models, directly training a video VAE without considering the compatibility with existing T2I models will result in a latent space gap between them, which will take huge computational resources for training to bridge the gap even with the T2I models as initialization.",133,Quantization
https://paperswithcode.com/paper/gnn-rag-graph-neural-retrieval-for-large,GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning,cmavro/gnn-rag,https://github.com/cmavro/gnn-rag,30 May 2024,"In our GNN-RAG framework, the GNN acts as a dense subgraph reasoner to extract useful graph information, while the LLM leverages its natural language processing ability for ultimate KGQA.",96,"Knowledge Graphs,Graph Question Answering"
https://paperswithcode.com/paper/alice-in-wonderland-simple-tasks-showing,Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models,laion-ai/aiw,https://github.com/laion-ai/aiw,4 Jun 2024,"Large Language Models (LLMs) are often described as being instances of foundation models - that is, models that transfer strongly across various tasks and conditions in few-show or zero-shot manner, while exhibiting scaling laws that predict function improvement when increasing the pre-training scale.",42,Common Sense Reasoning
https://paperswithcode.com/paper/transformers-are-ssms-generalized-models-and,Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality,state-spaces/mamba,https://github.com/state-spaces/mamba,31 May 2024,"While Transformers have been the main architecture behind deep learning's success in language modeling, state-space models (SSMs) such as Mamba have recently been shown to match or outperform Transformers at small to medium scale.","10,907",Language Modelling
https://paperswithcode.com/paper/textit-s-3-gaussian-self-supervised-street,$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving,nnanhuang/s3gaussian,https://github.com/nnanhuang/s3gaussian,30 May 2024,Photorealistic 3D reconstruction of street scenes is a critical technique for developing real-world simulators for autonomous driving.,223,"3D Scene Reconstruction,3D Reconstruction"
https://paperswithcode.com/paper/autocoder-enhancing-code-large-language-model,AutoCoder: Enhancing Code Large Language Model with \textsc{AIEV-Instruct},bin123apple/autocoder,https://github.com/bin123apple/autocoder,23 May 2024,"We introduce AutoCoder, the first Large Language Model to surpass GPT-4 Turbo (April 2024) and GPT-4o in pass@1 on the Human Eval benchmark test ($\mathbf{90. 9\%}$ vs. $\mathbf{90. 2\%}$).",677,"Code Completion,Class-level Code Generation"
https://paperswithcode.com/paper/a-decoder-only-foundation-model-for-time,A decoder-only foundation model for time-series forecasting,google-research/timesfm,https://github.com/google-research/timesfm,14 Oct 2023,"Motivated by recent advances in large language models for Natural Language Processing (NLP), we design a time-series foundation model for forecasting whose out-of-the-box zero-shot performance on a variety of public datasets comes close to the accuracy of state-of-the-art supervised forecasting models for each individual dataset.","2,818","Time Series,Decoder"
https://paperswithcode.com/paper/cross-modality-jailbreak-and-mismatched,Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models,dirtycomputer/o2m_attack,https://github.com/dirtycomputer/o2m_attack,26 May 2024,"Security concerns related to Large Language Models (LLMs) have been extensively explored, yet the safety implications for Multimodal Large Language Models (MLLMs), particularly in medical contexts (MedMLLMs), remain insufficiently studied.",38,Other
https://paperswithcode.com/paper/show-don-t-tell-aligning-language-models-with,"Show, Don't Tell: Aligning Language Models with Demonstrated Feedback",SALT-NLP/demonstrated-feedback,https://github.com/SALT-NLP/demonstrated-feedback,2 Jun 2024,"Across our benchmarks and user study, we find that win-rates for DITTO outperform few-shot prompting, supervised fine-tuning, and other self-play methods by an average of 19% points.",61,"Language Modelling,Imitation Learning"
https://paperswithcode.com/paper/block-transformer-global-to-local-language,Block Transformer: Global-to-Local Language Modeling for Fast Inference,itsnamgyu/block-transformer,https://github.com/itsnamgyu/block-transformer,4 Jun 2024,"We notice that these costs stem from applying self-attention on the global context, therefore we isolate the expensive bottlenecks of global modeling to lower layers and apply fast local modeling in upper layers.",34,Language Modelling
https://paperswithcode.com/paper/the-road-less-scheduled,The Road Less Scheduled,facebookresearch/schedule_free,https://github.com/facebookresearch/schedule_free,24 May 2024,"Existing learning rate schedules that do not require specification of the optimization stopping step T are greatly out-performed by learning rate schedules that depend on T. We propose an approach that avoids the need for this stopping time by eschewing the use of schedules entirely, while exhibiting state-of-the-art performance compared to schedules across a wide family of problems ranging from convex problems to large-scale deep learning problems.","1,474",Scheduling
https://paperswithcode.com/paper/neighborhood-enhanced-supervised-contrastive,Neighborhood-Enhanced Supervised Contrastive Learning for Collaborative Filtering,PeiJieSun/NESCL,https://github.com/PeiJieSun/NESCL,18 Feb 2024,"Using the graph-based collaborative filtering model as our backbone and following the same data augmentation methods as the existing contrastive learning model SGL, we effectively enhance the performance of the recommendation model.",103,"Contrastive Learning,Collaborative Filtering"
https://paperswithcode.com/paper/docs2kg-unified-knowledge-graph-construction,Docs2KG: Unified Knowledge Graph Construction from Heterogeneous Documents Assisted by Large Language Models,AI4WA/Docs2KG,https://github.com/AI4WA/Docs2KG,5 Jun 2024,"Even for a conservative estimate, 80% of enterprise data reside in unstructured files, stored in data lakes that accommodate heterogeneous formats.",46,"graph construction,Data Integration"
https://paperswithcode.com/paper/self-taught-recognizer-toward-unsupervised,Self-Taught Recognizer: Toward Unsupervised Adaptation for Speech Foundation Models,yuchen005/star-adapt,https://github.com/yuchen005/star-adapt,23 May 2024,"We propose an unsupervised adaptation framework, Self-TAught Recognizer (STAR), which leverages unlabeled data to enhance the robustness of automatic speech recognition (ASR) systems in diverse target domains, such as noise and accents.",127,"Automatic Speech Recognition (ASR),Automatic Speech Recognition"
https://paperswithcode.com/paper/motionfollower-editing-video-motion-via,MotionFollower: Editing Video Motion via Lightweight Score-Guided Diffusion,Francis-Rings/MotionFollower,https://github.com/Francis-Rings/MotionFollower,30 May 2024,"In this paper, we propose MotionFollower, a lightweight score-guided diffusion model for video motion editing.",70,"Image Animation,Denoising"
https://paperswithcode.com/paper/l-magic-language-model-assisted-generation-of,L-MAGIC: Language Model Assisted Generation of Images with Coherence,intellabs/mmpano,https://github.com/intellabs/mmpano,3 Jun 2024,"However, the lack of global scene layout priors leads to subpar outputs with duplicated objects (e. g., multiple beds in a bedroom) or requires time-consuming human text inputs for each view.",49,"Language Modelling,Depth Estimation"
https://paperswithcode.com/paper/craftsman-high-fidelity-mesh-generation-with,CraftsMan: High-fidelity Mesh Generation with 3D Native Generation and Interactive Geometry Refiner,wyysf-98/craftsman,https://github.com/wyysf-98/craftsman,23 May 2024,"We present a novel generative 3D modeling system, coined CraftsMan, which can generate high-fidelity 3D geometries with highly varied shapes, regular mesh topologies, and detailed surfaces, and, notably, allows for refining the geometry in an interactive manner.",274,3D Generation
https://paperswithcode.com/paper/awq-activation-aware-weight-quantization-for,AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration,internlm/lmdeploy,https://github.com/internlm/lmdeploy,1 Jun 2023,"We then propose to search for the optimal per-channel scaling that protects the salient weights by observing the activation, not weights.","2,886","Common Sense Reasoning,Autonomous Driving"
https://paperswithcode.com/paper/kan-kolmogorov-arnold-networks,KAN: Kolmogorov-Arnold Networks,Blealtan/efficient-kan,https://github.com/Blealtan/efficient-kan,30 Apr 2024,"Inspired by the Kolmogorov-Arnold representation theorem, we propose Kolmogorov-Arnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs).","3,265",Other
https://paperswithcode.com/paper/finrobot-an-open-source-ai-agent-platform-for,FinRobot: An Open-Source AI Agent Platform for Financial Applications using Large Language Models,ai4finance-foundation/finrobot,https://github.com/ai4finance-foundation/finrobot,23 May 2024,"As financial institutions and professionals increasingly incorporate Large Language Models (LLMs) into their workflows, substantial barriers, including proprietary data and specialized knowledge, persist between the finance sector and the AI community.",904,"Decision Making,AI Agent"
https://paperswithcode.com/paper/freshdiskann-a-fast-and-accurate-graph-based,FreshDiskANN: A Fast and Accurate Graph-Based ANN Index for Streaming Similarity Search,microsoft/diskann,https://github.com/microsoft/diskann,20 May 2021,Approximate nearest neighbor search (ANNS) is a fundamental building block in information retrieval with graph-based indices being the current state-of-the-art and widely used in the industry.,911,"Retrieval,Information Retrieval"
https://paperswithcode.com/paper/rlhf-workflow-from-reward-modeling-to-online,RLHF Workflow: From Reward Modeling to Online RLHF,rlhflow/online-rlhf,https://github.com/rlhflow/online-rlhf,13 May 2024,"We present the workflow of Online Iterative Reinforcement Learning from Human Feedback (RLHF) in this technical report, which is widely reported to outperform its offline counterpart by a large margin in the recent large language model (LLM) literature.",243,"Language Modelling,Chatbot"
https://paperswithcode.com/paper/openrlhf-an-easy-to-use-scalable-and-high,"OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework",OpenLLMAI/OpenRLHF,https://github.com/OpenLLMAI/OpenRLHF,20 May 2024,"However, unlike pretraining or fine-tuning a single model, scaling reinforcement learning from human feedback (RLHF) for training large language models poses coordination challenges across four models.","1,532","Scheduling,reinforcement-learning"
https://paperswithcode.com/paper/improving-diffusion-models-for-virtual-try-on,Improving Diffusion Models for Virtual Try-on,yisol/IDM-VTON,https://github.com/yisol/IDM-VTON,8 Mar 2024,"Finally, we present a customization method using a pair of person-garment images, which significantly improves fidelity and authenticity.","2,787",Virtual Try-on
https://paperswithcode.com/paper/relu-kan-new-kolmogorov-arnold-networks-that,"ReLU-KAN: New Kolmogorov-Arnold Networks that Only Need Matrix Addition, Dot Multiplication, and ReLU",quiqi/relu_kan,https://github.com/quiqi/relu_kan,4 Jun 2024,"Limited by the complexity of basis function (B-spline) calculations, Kolmogorov-Arnold Networks (KAN) suffer from restricted parallel computing capability on GPUs.",27,Other
https://paperswithcode.com/paper/dreamphysics-learning-physical-properties-of,DreamPhysics: Learning Physical Properties of Dynamic 3D Gaussians with Video Diffusion Priors,tyhuang0428/dreamphysics,https://github.com/tyhuang0428/dreamphysics,3 Jun 2024,"One solution is to animate 3D scenes with physics-based simulation, and the other is to learn the deformation of static 3D objects with the distillation of video generative models.",137,Other
https://paperswithcode.com/paper/sayself-teaching-llms-to-express-confidence,SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales,xu1868/sayself,https://github.com/xu1868/sayself,31 May 2024,"Large language models (LLMs) often generate inaccurate or fabricated information and generally fail to indicate their confidence, which limits their broader applications.",46,Other
https://paperswithcode.com/paper/vista-a-generalizable-driving-world-model,Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability,opendrivelab/vista,https://github.com/opendrivelab/vista,27 May 2024,"In this paper, we present Vista, a generalizable driving world model with high fidelity and versatile controllability.",302,"Video Generation,Autonomous Driving"
https://paperswithcode.com/paper/demonstration-of-db-gpt-next-generation-data,Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models,eosphoros-ai/db-gpt,https://github.com/eosphoros-ai/db-gpt,16 Apr 2024,The recent breakthroughs in large language models (LLMs) are positioned to transition many areas of software.,"11,821","Text-To-SQL,Data Interaction"
https://paperswithcode.com/paper/xrec-large-language-models-for-explainable,XRec: Large Language Models for Explainable Recommendation,hkuds/xrec,https://github.com/hkuds/xrec,4 Jun 2024,"We introduce a model-agnostic framework called XRec, which enables LLMs to provide comprehensive explanations for user behaviors in recommender systems.",30,"Decision Making,Collaborative Filtering"
https://paperswithcode.com/paper/zerosmooth-training-free-diffuser-adaptation,ZeroSmooth: Training-free Diffuser Adaptation for High Frame Rate Video Generation,ssyang2020/ZeroSmooth,https://github.com/ssyang2020/ZeroSmooth,3 Jun 2024,Previous methods promote the frame rate by either training a video interpolation model in pixel space as a postprocessing stage or training an interpolation model in latent space for a specific base video model.,51,Video Generation
https://paperswithcode.com/paper/fredf-learning-to-forecast-in-frequency,FreDF: Learning to Forecast in Frequency Domain,master-plc/fredf,https://github.com/master-plc/fredf,4 Feb 2024,Time series modeling is uniquely challenged by the presence of autocorrelation in both historical and label sequences.,20,Time Series
https://paperswithcode.com/paper/ufo-a-ui-focused-agent-for-windows-os,UFO: A UI-Focused Agent for Windows OS Interaction,microsoft/UFO,https://github.com/microsoft/UFO,8 Feb 2024,"We introduce UFO, an innovative UI-Focused agent to fulfill user requests tailored to applications on Windows OS, harnessing the capabilities of GPT-Vision.","5,648",Navigate
https://paperswithcode.com/paper/sparsedrive-end-to-end-autonomous-driving-via,SparseDrive: End-to-End Autonomous Driving via Sparse Scene Representation,swc-17/sparsedrive,https://github.com/swc-17/sparsedrive,30 May 2024,"To this end, we explore the sparse representation and review the task design for end-to-end autonomous driving, proposing a new paradigm named SparseDrive.",81,"Autonomous Driving,Attribute"
https://paperswithcode.com/paper/sparsectrl-adding-sparse-controls-to-text-to,SparseCtrl: Adding Sparse Controls to Text-to-Video Diffusion Models,guoyww/animatediff,https://github.com/guoyww/animatediff,28 Nov 2023,"The development of text-to-video (T2V), i. e., generating videos with a given text prompt, has been significantly advanced in recent years.","9,459",Video Generation
https://paperswithcode.com/paper/emotion2vec-self-supervised-pre-training-for,emotion2vec: Self-Supervised Pre-Training for Speech Emotion Representation,alibaba-damo-academy/FunASR,https://github.com/alibaba-damo-academy/FunASR,23 Dec 2023,"To the best of our knowledge, emotion2vec is the first universal representation model in various emotion-related tasks, filling a gap in the field.","4,126","Sentiment Analysis,Self-Supervised Learning"
https://paperswithcode.com/paper/llamp-large-language-model-made-powerful-for,LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation,chiang-yuan/llamp,https://github.com/chiang-yuan/llamp,30 Jan 2024,"Reducing hallucination of Large Language Models (LLMs) is imperative for use in the sciences, where reliability and reproducibility are crucial.",33,"Knowledge Distillation,Hallucination"
https://paperswithcode.com/paper/minicpm-unveiling-the-potential-of-small,MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies,openbmb/minicpm,https://github.com/openbmb/minicpm,9 Apr 2024,"For data scaling, we introduce a Warmup-Stable-Decay (WSD) learning rate scheduler (LRS), conducive to continuous training and domain adaptation.","4,225",Domain Adaptation
https://paperswithcode.com/paper/lw-detr-a-transformer-replacement-to-yolo-for,LW-DETR: A Transformer Replacement to YOLO for Real-Time Detection,atten4vis/lw-detr,https://github.com/atten4vis/lw-detr,5 Jun 2024,"In this paper, we present a light-weight detection transformer, LW-DETR, which outperforms YOLOs for real-time object detection.",22,"object-detection,Decoder"
https://paperswithcode.com/paper/parameter-inverted-image-pyramid-networks,Parameter-Inverted Image Pyramid Networks,opengvlab/piip,https://github.com/opengvlab/piip,6 Jun 2024,"Our core idea is to use models with different parameter sizes to process different resolution levels of the image pyramid, thereby balancing computational efficiency and performance.",21,"Image Classification,Computational Efficiency"
https://paperswithcode.com/paper/faithful-logical-reasoning-via-symbolic-chain,Faithful Logical Reasoning via Symbolic Chain-of-Thought,aiden0526/symbcot,https://github.com/aiden0526/symbcot,28 May 2024,"Technically, building upon an LLM, SymbCoT 1) first translates the natural language context into the symbolic format, and then 2) derives a step-by-step plan to solve the problem with symbolic logical rules, 3) followed by a verifier to check the translation and reasoning chain.",78,Logical Reasoning
https://paperswithcode.com/paper/making-images-real-again-a-comprehensive,Making Images Real Again: A Comprehensive Survey on Deep Image Composition,bcmi/Awesome-Image-Composition,https://github.com/bcmi/Awesome-Image-Composition,28 Jun 2021,"We have also contributed the first image composition toolbox: libcom https://github. com/bcmi/libcom, which assembles 10+ image composition related functions (e. g., image blending, image harmonization, object placement, shadow generation, generative composition).",897,Image Harmonization
https://paperswithcode.com/paper/masknet-introducing-feature-wise,MaskNet: Introducing Feature-Wise Multiplication to CTR Ranking Models by Instance-Guided Mask,UlionTse/mlgb,https://github.com/UlionTse/mlgb/blob/main/mlgb/torch/models/ranking.py,9 Feb 2021,We also turn the feed-forward layer in DNN model into a mixture of addictive and multiplicative feature interactions by proposing MaskBlock in this paper.,367,"Recommendation Systems,Click-Through Rate Prediction"
https://paperswithcode.com/paper/once-for-all-controllable-generative-image,Once-for-All: Controllable Generative Image Compression with Dynamic Granularity Adaption,lianqi1008/Control-GIC,https://github.com/lianqi1008/Control-GIC,2 Jun 2024,"To overcome this challenge, this paper proposes a Controllable Generative Image Compression framework, Control-GIC, the first capable of fine-grained bitrate adaption across a broad spectrum while ensuring high-fidelity and generality compression.",27,Image Compression
https://paperswithcode.com/paper/pepnet-parameter-and-embedding-personalized,PEPNet: Parameter and Embedding Personalized Network for Infusing with Personalized Prior Information,UlionTse/mlgb,https://github.com/UlionTse/mlgb,2 Feb 2023,"By infusing personalized selection of Embedding and personalized modification of DNN parameters, PEPNet tailored to the interests of each individual obtains significant performance gains, with online improvements exceeding 1\% in multiple task metrics across multiple domains.",367,Recommendation Systems
https://paperswithcode.com/paper/grokfast-accelerated-grokking-by-amplifying,Grokfast: Accelerated Grokking by Amplifying Slow Gradients,ironjr/grokfast,https://github.com/ironjr/grokfast,30 May 2024,One puzzling artifact in machine learning dubbed grokking is where delayed generalization is achieved tenfolds of iterations after near perfect overfitting to the training data.,53,Other
https://paperswithcode.com/paper/nerf-on-the-go-exploiting-uncertainty-for,NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild,cvg/nerf-on-the-go,https://github.com/cvg/nerf-on-the-go,29 May 2024,"Neural Radiance Fields (NeRFs) have shown remarkable success in synthesizing photorealistic views from multi-view images of static scenes, but face challenges in dynamic, real-world environments with distractors like moving objects, shadows, and lighting changes.",74,Other
https://paperswithcode.com/paper/deepseek-v2-a-strong-economical-and-efficient,"DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model",deepseek-ai/deepseek-v2,https://github.com/deepseek-ai/deepseek-v2,7 May 2024,"MLA guarantees efficient inference through significantly compressing the Key-Value (KV) cache into a latent vector, while DeepSeekMoE enables training strong models at an economical cost through sparse computation.","2,476","Reinforcement Learning (RL),Language Modelling"
https://paperswithcode.com/paper/nvs-solver-video-diffusion-model-as-zero-shot,NVS-Solver: Video Diffusion Model as Zero-Shot Novel View Synthesizer,zhu-zhiyu/nvs_solver,https://github.com/zhu-zhiyu/nvs_solver,24 May 2024,"By harnessing the potent generative capabilities of pre-trained large video diffusion models, we propose NVS-Solver, a new novel view synthesis (NVS) paradigm that operates \textit{without} the need for training.",144,Novel View Synthesis
https://paperswithcode.com/paper/the-unreasonable-effectiveness-of-eccentric,The Unreasonable Effectiveness of Eccentric Automatic Prompts,stanfordnlp/dspy,https://github.com/stanfordnlp/dspy,9 Feb 2024,"Given the combinatorial complexity, and thus computation time, of experimenting with hand-tuning prompts for large black-box models, we then compared the performance of the best ""positive thinking"" prompt against the output of systematic prompt optimization.","12,522","GSM8K,Arithmetic Reasoning"
https://paperswithcode.com/paper/efficient-guided-generation-for-llms,Efficient Guided Generation for Large Language Models,normal-computing/outlines,https://github.com/normal-computing/outlines,19 Jul 2023,In this article we show how the problem of neural text generation can be constructively reformulated in terms of transitions between the states of a finite-state machine.,"6,521","Text Generation,Language Modelling"
https://paperswithcode.com/paper/assisting-in-writing-wikipedia-like-articles,Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models,assafelovic/gpt-researcher,https://github.com/assafelovic/gpt-researcher,22 Feb 2024,"We study how to apply large language models to write grounded and organized long-form articles from scratch, with comparable breadth and depth to Wikipedia pages.","12,531",Retrieval
https://paperswithcode.com/paper/graphany-a-foundation-model-for-node,GraphAny: A Foundation Model for Node Classification on Any Graph,deepgraphlearning/graphany,https://github.com/deepgraphlearning/graphany,30 May 2024,Traditional graph ML models such as graph neural networks (GNNs) trained on graphs cannot perform inference on a new graph with feature and label spaces different from the training ones.,58,Node Classification
https://paperswithcode.com/paper/direct-3d-learning-direct-text-to-3d,DIRECT-3D: Learning Direct Text-to-3D Generation on Massive Noisy 3D Data,qihao067/direct3d,https://github.com/qihao067/direct3d,6 Jun 2024,"Unlike recent 3D generative models that rely on clean and well-aligned 3D data, limiting them to single or few-class generation, our model is directly trained on extensive noisy and unaligned `in-the-wild' 3D assets, mitigating the key challenge (i. e., data scarcity) in large-scale 3D generation.",14,"Text to 3D,3D Generation"
https://paperswithcode.com/paper/learning-1d-causal-visual-representation-with,Learning 1D Causal Visual Representation with De-focus Attention Networks,opengvlab/de-focus-attention-networks,https://github.com/opengvlab/de-focus-attention-networks,6 Jun 2024,"The issue of ""over-focus"" hinders the model's ability to extract diverse visual features and to receive effective gradients for optimization.",16,Other
https://paperswithcode.com/paper/do-anything-now-characterizing-and-evaluating,"""Do Anything Now"": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models",verazuo/jailbreak_llms,https://github.com/verazuo/jailbreak_llms,7 Aug 2023,We hope that our study can facilitate the research community and LLM vendors in promoting safer and regulated LLMs.,299,Community Detection
https://paperswithcode.com/paper/flashrag-a-modular-toolkit-for-efficient,FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research,ruc-nlpir/flashrag,https://github.com/ruc-nlpir/flashrag,22 May 2024,"With the advent of Large Language Models (LLMs), the potential of Retrieval Augmented Generation (RAG) techniques have garnered considerable research attention.",725,Retrieval
https://paperswithcode.com/paper/what-makes-good-in-context-examples-for-gpt-3,What Makes Good In-Context Examples for GPT-$3$?,stanfordnlp/dsp,https://github.com/stanfordnlp/dsp,17 Jan 2021,"Inspired by the recent success of leveraging a retrieval module to augment large-scale neural network models, we propose to retrieve examples that are semantically-similar to a test sample to formulate its corresponding prompt.","12,532","Natural Language Understanding,Few-Shot Learning"
https://paperswithcode.com/paper/inf-dit-upsampling-any-resolution-image-with,Inf-DiT: Upsampling Any-Resolution Image with Memory-Efficient Diffusion Transformer,thudm/inf-dit,https://github.com/thudm/inf-dit,7 May 2024,"However, due to a quadratic increase in memory during generating ultra-high-resolution images (e. g. 4096*4096), the resolution of generated images is often limited to 1024*1024.",208,"Super-Resolution,Image Generation"
https://paperswithcode.com/paper/mistral-7b,Mistral 7B,skypilot-org/skypilot,https://github.com/skypilot-org/skypilot,10 Oct 2023,"We introduce Mistral 7B v0. 1, a 7-billion-parameter language model engineered for superior performance and efficiency.","6,041","Chatbot,Arithmetic Reasoning"
https://paperswithcode.com/paper/anytool-self-reflective-hierarchical-agents,"AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls",dyabel/anytool,https://github.com/dyabel/anytool,6 Feb 2024,We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate.,188,"Large Language Model,Language Modelling"
https://paperswithcode.com/paper/training-language-models-to-follow,Training language models to follow instructions with human feedback,hiyouga/llama-efficient-tuning,https://github.com/hiyouga/llama-efficient-tuning,4 Mar 2022,"In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback.","23,960",Other
https://paperswithcode.com/paper/freb-tqa-a-fine-grained-robustness-evaluation,FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering,hiyouga/llama-factory,https://github.com/hiyouga/llama-factory,29 Apr 2024,"To investigate these aspects, we create and publish a novel TQA evaluation benchmark in English.","23,955",Question Answering
https://paperswithcode.com/paper/simpo-simple-preference-optimization-with-a,SimPO: Simple Preference Optimization with a Reference-Free Reward,princeton-nlp/simpo,https://github.com/princeton-nlp/simpo,23 May 2024,"Our top-performing model, built on Llama3-8B-Instruct, achieves a remarkable 44. 7 length-controlled win rate on AlpacaEval 2 -- surpassing Claude 3 Opus on the leaderboard, and a 33. 8 win rate on Arena-Hard -- making it the strongest 8B open-source model.",409,Instruction Following
https://paperswithcode.com/paper/2309-06180,Efficient Memory Management for Large Language Model Serving with PagedAttention,vllm-project/vllm,https://github.com/vllm-project/vllm,12 Sep 2023,"On top of it, we build vLLM, an LLM serving system that achieves (1) near-zero waste in KV cache memory and (2) flexible sharing of KV cache within and across requests to further reduce memory usage.","20,731","Large Language Model,Language Modelling"
https://paperswithcode.com/paper/learning-to-cache-accelerating-diffusion,Learning-to-Cache: Accelerating Diffusion Transformer via Layer Caching,horseee/learning-to-cache,https://github.com/horseee/learning-to-cache,3 Jun 2024,"To address the challenge of the exponential search space in deep models for identifying layers to cache and remove, we propose a novel differentiable optimization objective.",27,Denoising
https://paperswithcode.com/paper/prometheus-inducing-fine-grained-evaluation,Prometheus: Inducing Fine-grained Evaluation Capability in Language Models,stanford-oval/storm,https://github.com/stanford-oval/storm,12 Oct 2023,"We first construct the Feedback Collection, a new dataset that consists of 1K fine-grained score rubrics, 20K instructions, and 100K responses and language feedback generated by GPT-4.","4,619","Large Language Model,Language Modelling"
https://paperswithcode.com/paper/mmbench-is-your-multi-modal-model-an-all,MMBench: Is Your Multi-modal Model an All-around Player?,InternLM/opencompass,https://github.com/InternLM/opencompass,12 Jul 2023,"In response to these challenges, we propose MMBench, a novel multi-modality benchmark.","2,948",Visual Question Answering
https://paperswithcode.com/paper/video-understanding-with-large-language,Video Understanding with Large Language Models: A Survey,yunlong10/awesome-llms-for-video-understanding,https://github.com/yunlong10/awesome-llms-for-video-understanding,29 Dec 2023,"With the burgeoning growth of online video platforms and the escalating volume of video content, the demand for proficient video understanding tools has intensified markedly.",805,Video Understanding
https://paperswithcode.com/paper/improved-distribution-matching-distillation,Improved Distribution Matching Distillation for Fast Image Synthesis,tianweiy/DMD2,https://github.com/tianweiy/DMD2,23 May 2024,Recent approaches have shown promises distilling diffusion models into efficient one-step generators.,254,Image Generation
https://paperswithcode.com/paper/gens-generalizable-neural-surface-1,GenS: Generalizable Neural Surface Reconstruction from Multi-View Images,prstrive/gens,https://github.com/prstrive/gens,,"Meanwhile, we introduce a multi-scale feature-metric consistency to impose the multi-view consistency in a more discriminative multi-scale feature space, which is robust to the failures of the photometric consistency.",26,Surface Reconstruction
https://paperswithcode.com/paper/mora-enabling-generalist-video-generation-via,Mora: Enabling Generalist Video Generation via A Multi-Agent Framework,lichao-sun/mora,https://github.com/lichao-sun/mora,20 Mar 2024,Sora is the first large-scale generalist video generation model that garnered significant attention across society.,"1,398","Text-to-Video Generation,Image to Video Generation"
https://paperswithcode.com/paper/the-benefits-of-a-concise-chain-of-thought-on,The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models,matthewrenze/jhu-concise-cot,https://github.com/matthewrenze/jhu-concise-cot,11 Jan 2024,We evaluated this using GPT-3. 5 and GPT-4 with a multiple-choice question-and-answer (MCQA) benchmark.,19,"Multiple-choice,Math"
https://paperswithcode.com/paper/ader-a-comprehensive-benchmark-for-multi,ADer: A Comprehensive Benchmark for Multi-class Visual Anomaly Detection,zhangzjn/ader,https://github.com/zhangzjn/ader,5 Jun 2024,"This paper addresses this issue by proposing a comprehensive visual anomaly detection benchmark, \textbf{\textit{ADer}}, which is a modular framework that is highly extensible for new methods.",89,"Lesion Detection,Anomaly Detection"
https://paperswithcode.com/paper/lean-workbook-a-large-scale-lean-problem-set,Lean Workbook: A large-scale Lean problem set formalized from natural language math problems,internlm/internlm-math,https://github.com/internlm/internlm-math,6 Jun 2024,Our results indicate that the synthetic data pipeline can provide useful training data and improve the performance of LLMs in translating and understanding complex mathematical problems and proofs.,326,"Math,Automated Theorem Proving"
https://paperswithcode.com/paper/deep-learning-for-camera-calibration-and,Deep Learning for Camera Calibration and Beyond: A Survey,kangliao929/awesome-deep-camera-calibration,https://github.com/kangliao929/awesome-deep-camera-calibration,19 Mar 2023,"In this paper, we provide a comprehensive survey of learning-based camera calibration techniques, by analyzing their strengths and limitations.",461,Camera Calibration
https://paperswithcode.com/paper/itransformer-inverted-transformers-are,iTransformer: Inverted Transformers Are Effective for Time Series Forecasting,thuml/Time-Series-Library,https://github.com/thuml/Time-Series-Library,10 Oct 2023,"These forecasters leverage Transformers to model the global dependencies over temporal tokens of time series, with each token formed by multiple variates of the same timestamp.","4,793","Time Series Forecasting,Time Series"
https://paperswithcode.com/paper/lumina-t2x-transforming-text-into-any,"Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers",alpha-vllm/lumina-t2x,https://github.com/alpha-vllm/lumina-t2x,9 May 2024,"Sora unveils the potential of scaling Diffusion Transformer for generating photorealistic images and videos at arbitrary resolutions, aspect ratios, and durations, yet it still lacks sufficient implementation details.","1,336",Other
https://paperswithcode.com/paper/audio-flamingo-a-novel-audio-language-model,Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities,NVIDIA/audio-flamingo,https://github.com/NVIDIA/audio-flamingo,2 Feb 2024,Augmenting large language models (LLMs) to understand audio -- including non-speech sounds and non-verbal speech -- is critically important for diverse real-world applications of LLMs.,24,"Few-Shot Learning,Acoustic Scene Classification"
https://paperswithcode.com/paper/turning-whisper-into-real-time-transcription,Turning Whisper into Real-Time Transcription System,ufal/whisper_streaming,https://github.com/ufal/whisper_streaming,27 Jul 2023,"Whisper is one of the recent state-of-the-art multilingual speech recognition and translation models, however, it is not designed for real time transcription.","1,278","Speech Recognition,speech-recognition"
https://paperswithcode.com/paper/open-yolo-3d-towards-fast-and-accurate-open,Open-YOLO 3D: Towards Fast and Accurate Open-Vocabulary 3D Instance Segmentation,aminebdj/openyolo3d,https://github.com/aminebdj/openyolo3d,4 Jun 2024,"To this end, we propose a fast yet accurate open-vocabulary 3D instance segmentation approach, named Open-YOLO 3D, that effectively leverages only 2D object detection from multi-view RGB images for open-vocabulary 3D instance segmentation.",24,"object-detection,3D Instance Segmentation"
https://paperswithcode.com/paper/audio-mamba-bidirectional-state-space-model,Audio Mamba: Bidirectional State Space Model for Audio Representation Learning,mhamzaerol/audio-mamba-aum,https://github.com/mhamzaerol/audio-mamba-aum,5 Jun 2024,"Transformers have rapidly become the preferred choice for audio classification, surpassing methods based on CNNs.",19,"Representation Learning,Audio Classification"
https://paperswithcode.com/paper/easyspider-a-no-code-visual-system-for,EasySpider: A No-Code Visual System for Crawling the Web,NaiboWang/EasySpider,https://github.com/NaiboWang/EasySpider,,"As such, web-crawling is an essential tool for both computational and non-computational scientists to conduct research.","27,413","Marketing,Data Integration"
https://paperswithcode.com/paper/pruner-zero-evolving-symbolic-pruning-metric,Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models,pprp/pruner-zero,https://github.com/pprp/pruner-zero,5 Jun 2024,"In particular, we devise an elaborate search space encompassing the existing pruning metrics to discover the potential symbolic pruning metric.",26,Language Modelling
https://paperswithcode.com/paper/text-to-image-rectified-flow-as-plug-and-play,Text-to-Image Rectified Flow as Plug-and-Play Priors,yangxiaofeng/rectified_flow_prior,https://github.com/yangxiaofeng/rectified_flow_prior,5 Jun 2024,"Besides the generative capabilities of diffusion priors, motivated by the unique time-symmetry properties of rectified flow models, a variant of our method can additionally perform image inversion.",21,"Text to 3D,3D Generation"
https://paperswithcode.com/paper/how-abilities-in-large-language-models-are,How Abilities in Large Language Models are Affected by Supervised Fine-tuning Data Composition,wangrongsheng/caregpt,https://github.com/wangrongsheng/caregpt,9 Oct 2023,"We propose four intriguing research questions to explore the association between model performance and various factors including data amount, composition ratio, model size and SFT strategies.",587,"Instruction Following,Code Generation"
https://paperswithcode.com/paper/mathematical-supplement-for-the-texttt-gsplat,Mathematical Supplement for the $\texttt{gsplat}$ Library,nerfstudio-project/gsplat,https://github.com/nerfstudio-project/gsplat,4 Dec 2023,"This report provides the mathematical details of the gsplat library, a modular toolbox for efficient differentiable Gaussian splatting, as proposed by Kerbl et al.",957,Other
https://paperswithcode.com/paper/looking-backward-streaming-video-to-video,Looking Backward: Streaming Video-to-Video Translation with Feature Banks,Jeff-LiangF/streamv2v,https://github.com/Jeff-LiangF/streamv2v,24 May 2024,"This paper introduces StreamV2V, a diffusion model that achieves real-time streaming video-to-video (V2V) translation with user prompts.",305,Translation
https://paperswithcode.com/paper/prometheus-2-an-open-source-language-model,Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models,prometheus-eval/prometheus-eval,https://github.com/prometheus-eval/prometheus-eval,2 May 2024,Proprietary LMs such as GPT-4 are often employed to assess the quality of responses from various LMs.,602,Language Modelling
https://paperswithcode.com/paper/tetrahedron-splatting-for-3d-generation,Tetrahedron Splatting for 3D Generation,fudan-zvg/tet-splatting,https://github.com/fudan-zvg/tet-splatting,3 Jun 2024,"Using a signed distance field and Marching Tetrahedra, DMTet allows for precise mesh extraction and real-time rendering but is limited in handling large topological changes in meshes, leading to optimization challenges.",78,3D Generation
https://paperswithcode.com/paper/a-challenger-to-gpt-4v-early-explorations-of,A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise,bradyfu/awesome-multimodal-large-language-models,https://github.com/bradyfu/awesome-multimodal-large-language-models,19 Dec 2023,"They endow Large Language Models (LLMs) with powerful capabilities in visual understanding, enabling them to tackle diverse multi-modal tasks.","9,901",Visual Reasoning
https://paperswithcode.com/paper/hanet-a-hierarchical-attention-network-for,HANet: A Hierarchical Attention Network for Change Detection With Bitemporal Very-High-Resolution Remote Sensing Images,faceonlive/ai-research,https://gitlab.com/faceonlive/ai-research,14 Apr 2024,"Benefiting from the developments in deep learning technology, deep-learning-based algorithms employing automatic feature extraction have achieved remarkable performance on the change detection (CD) task.",294,Change Detection
